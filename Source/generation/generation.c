#include "generation/generation.h"
#include "basics.h"
#include "stdio.h"
#include "grammar/grammar.h"
#include "grammar/lalrMachine.h"

static char* generationPath = "output/";
static char* baseOutputPath = "output/parsers/";
static char* linkToRepo = "https://github.com/ClaudioMota/UCC";

typedef struct
{
  char** fullNames;
  int* prodToFullName;
  ProductionOption** fullNameToOption;
  int fullNameCount;
} FullNameMaps;

static void generateHeaderGuardsStart(FILE* file, char* headerTitle)
{
  char fullTitle[STRING_LENGTH*3];
  strcpy(fullTitle, headerTitle);
  strcat(fullTitle, "_HEADER");
  fprintf(file, "#ifndef %s\n", fullTitle);
  fprintf(file, "#define %s 1\n", fullTitle);
  fprintf(file, "#ifdef __cplusplus\n");
  fprintf(file, "extern \"C\" {\n");
  fprintf(file, "#endif\n\n");
}

static void generateHeaderGuardsEnd(FILE* file)
{
  fprintf(file, "\n#ifdef __cplusplus\n");
  fprintf(file, "}\n");
  fprintf(file, "#endif\n");
  fprintf(file, "#endif\n");
}

static void generatedFileDisclaimer(FILE* file)
{
  fprintf(file, "// This file was generated by UCC. Manual changes are discouraged as they may be overwritten in future generations.\n");
  fprintf(file, "// See %s for more in information.\n\n", linkToRepo);
}

static bool generateParserHeader(FILE* file, Grammar* grammar, char* namespace)
{
  char headerTitle[STRING_LENGTH*2];
  strcpy(headerTitle, namespace);
  strcat(headerTitle, "_PARSER");

  generatedFileDisclaimer(file);
  generateHeaderGuardsStart(file, headerTitle);
  
  fprintf(file, "enum %s_Tokens\n{\n  %s_T_UNKNOWN = -2,\n  %s_T_END_OF_INPUT = -1", namespace, namespace, namespace);
  for(int i = 0; i < grammar->tokenCount; i++)
    fprintf(file, ",\n  %s_T_%s", namespace, grammar->tokens[i].name);
  fprintf(file, "\n};\n\n");

  fprintf(file, "extern int (**%s_lexerFunctions)(int* state, int input);\n", namespace);
  fprintf(file, "extern int %s_lexerFunctionCount;\n\n", namespace);
  fprintf(file, "bool %s_shouldIgnoreToken(Token* token);\n", namespace);
  fprintf(file, "bool %s_visit(Production* production, VisitData* visitData);\n", namespace);
  fprintf(file, "bool %s_visitNodes(Production* production, VisitData* visitData);\n", namespace);
  fprintf(file, "extern bool %s_nodeRedundancyTable[];\n\n", namespace);
  fprintf(file, "Parser %s_parse(Token* tokens, int productionStructSize);\n", namespace);

  generateHeaderGuardsEnd(file);

  return true;
}

static void generateTokenFunction(FILE* file, TokenExpr* token)
{
  fprintf(file, "static int func_%s(int* state, int input)\n{\n", token->name);
  fprintf(file, "  switch(*state)\n  {\n");
  for(int i = 0; i < token->stateMachine.stateCount; i++)
  {
    StateMachineState* state = token->stateMachine.states[i];
    fprintf(file, "    case %i:\n", state->index);
    fprintf(file,"    switch(input)\n    {\n      ");
    for(int j = 0; j < state->transitionCount; j++)
    {
      StateMachineTransition* transition = &state->transitions[j];
      for(int k = 0; k < SUPPORTED_CHARACTERS; k++)
        if(transition->values[k])
          fprintf(file,"case %i: ", k);
      fprintf(file,"*state = %i; break;\n      ", transition->target->index);
    }

    fprintf(file,"default: *state = LEXER_ERROR;\n    }\n    break;\n");
  }

  fprintf(file,"    default: *state = LEXER_ERROR;\n  }\n");
  fprintf(file, "  if(*state == LEXER_ERROR) return LEXER_ERROR;\n  switch(*state)\n  {\n    ");
  for(int i = 0; i < token->stateMachine.stateCount; i++)
    if(token->stateMachine.states[i]->accepted)
      fprintf(file,"case %i: ", i);

  fprintf(file,"return LEXER_ACCEPTED;\n    default: return LEXER_PROCESSING;\n  }\n}\n\n");
}

static void generateLexerSource(FILE* file, Grammar* grammar, char* namespace)
{
  for(int i = 0; i < grammar->tokenCount; i++) generateTokenFunction(file, &grammar->tokens[i]);

  fprintf(file, "static int (*functions[])(int* state, int input) = {");
  for(int i = 0; i < grammar->tokenCount; i++)
  {
    if(i) fprintf(file, ",");
    fprintf(file, "\n  func_%s", grammar->tokens[i].name);
  }

  fprintf(file, "\n};\n\nint (**%s_lexerFunctions)(int* state, int input) = functions;\n", namespace);
  fprintf(file, "int %s_lexerFunctionCount = %i;\n\n", namespace, grammar->tokenCount);
  fprintf(file, "bool %s_shouldIgnoreToken(Token* token)\n{\n  switch(token->type){\n    ", namespace);

  bool hasIgnored = false;
  for(int i = 0; i < grammar->tokenCount; i++)
    if(grammar->tokens[i].ignored)
    {
      hasIgnored = true;
      fprintf(file, "case %i: ", grammar->tokens[i].index);
    }
  if(hasIgnored) fprintf(file, "return true;\n    ");
  fprintf(file, "default: return false;\n  }\n");
  fprintf(file, "}\n\n");
}

static int getProductionFullName(ProductionOption* production, Grammar* grammar, char* output)
{
  int ret = 0;
  ProductionExpr* prodExpr = Grammar_getReduced(grammar, production->base);
  if(!prodExpr) prodExpr = production->base; 
  ret += strlen(prodExpr->name);
  if(output) strcpy(output, prodExpr->name);
  
  for(int i = 0; i < production->stepCount; i++)
  {
    ret++;
    if(output) strcat(output, "_");
    if(production->steps[i].token)
    {
      ret += strlen(production->steps[i].token->name);
      if(output) strcat(output, production->steps[i].token->name);
    }
    else
    {
      prodExpr = Grammar_getReduced(grammar, production->steps[i].production);
      if(!prodExpr) prodExpr = production->steps[i].production;
      ret += strlen(prodExpr->name);
      if(output) strcat(output, prodExpr->name);
    }
  }
  
  return ret;
}

static int maybeMapFullName(char* fullName, char** mappedFullNames, int* mapSize)
{
  for(int k = 0; k < *mapSize; k++)
    if(strcmp(mappedFullNames[k], fullName) == 0)
      return k;

  int length = strlen(fullName);
  char* copy = new(sizeof(char)*(length + 1));
  strcpy(copy, fullName);
  mappedFullNames[*mapSize] = copy;
  return (*mapSize)++;
}

static FullNameMaps createProductionFullNameMaps(Grammar* grammar)
{
  FullNameMaps ret;
  memset(&ret, 0, sizeof(ret));

  int optionIndex = 0, mapSize = 0;
  int maxFullNames = grammar->productionCount;
  for(int i = 0; i < grammar->productionCount; i++)
    maxFullNames += grammar->productions[i].optionCount;

  char** mappedFullNames = new(sizeof(char*)*maxFullNames);
  int* prodToFullName = new(sizeof(int)*grammar->productionCount);
  int* mapOptionToFullName = new(sizeof(char*)*maxFullNames);
  ProductionOption** mapFullNameToOption = new(sizeof(ProductionOption*)*maxFullNames);
  memset(mappedFullNames, 0, sizeof(char*)*maxFullNames);
  memset(prodToFullName, 0, sizeof(int)*grammar->productionCount);
  memset(mapOptionToFullName, 0, sizeof(int)*maxFullNames);
  memset(mapFullNameToOption, 0, sizeof(ProductionOption*)*maxFullNames);

  for(int i = 0; i < grammar->productionCount; i++)
  {
    ProductionExpr* prodExpr = Grammar_getReduced(grammar, &grammar->productions[i]);
    if(!prodExpr) prodExpr = &grammar->productions[i];
    char fullName[STRING_LENGTH + 1];
    strcpy(fullName, prodExpr->name);
    prodToFullName[i] = maybeMapFullName(fullName, mappedFullNames, &mapSize);

    for(int j = 0; j < grammar->productions[i].optionCount; j++)
    {
      ProductionOption* option = &grammar->productions[i].options[j];
      int length = getProductionFullName(option, grammar, nullptr);
      char fullName[length + 1];
      fullName[0] = '\0';
      getProductionFullName(option, grammar, fullName);
      int nameIndex = maybeMapFullName(fullName, mappedFullNames, &mapSize);
      mapOptionToFullName[optionIndex++] = nameIndex;
      mapFullNameToOption[nameIndex] = option;
    }
  }

  ret.fullNames = mappedFullNames;
  ret.prodToFullName = prodToFullName;
  ret.fullNameToOption = mapFullNameToOption;
  ret.fullNameCount = mapSize;
  delete(mapOptionToFullName);
  
  return ret;
}

static void clearFullNameMaps(FullNameMaps* fullNameMaps)
{
  for(int i = 0; i < fullNameMaps->fullNameCount; i++)
    if(fullNameMaps->fullNames[i]) delete(fullNameMaps->fullNames[i]);
  delete(fullNameMaps->prodToFullName);
  delete(fullNameMaps->fullNameToOption);
  delete(fullNameMaps->fullNames);
  memset(fullNameMaps, 0, sizeof(FullNameMaps));
}

static void generateProductionsHeader(FILE* file, FullNameMaps* maps, Grammar* grammar, LalrMachine* lalrMachine, char* namespace)
{
  char headerTitle[STRING_LENGTH*2];
  strcpy(headerTitle, namespace);
  strcat(headerTitle, "_PRODUCTIONS");
  generatedFileDisclaimer(file);
  generateHeaderGuardsStart(file, headerTitle);

  fprintf(file, "#include <stdbool.h>\n");
  fprintf(file, "#include <parsers/parser.h>\n\n");

  // Visit functions
  char* visitType = "extern VisitFunction ";
  fprintf(file, "%s%s_visit_defaultFunction;\n\n", visitType, namespace);
  for(int i = 0; i < maps->fullNameCount; i++)
    fprintf(file, "%s%s_visit_%s;\n", visitType, namespace, maps->fullNames[i]);

  // Productions enum
  fprintf(file, "\nenum %s_ProductionType\n{\n  %s_P_UNKNOWN", namespace, namespace);
  for(int i = 0; i < maps->fullNameCount; i++)
    if(maps->fullNameToOption[i] != nullptr) fprintf(file, ",\n  %s_P_%s", namespace, maps->fullNames[i]);
  fprintf(file, "\n};\n");

  // Productions structs
  for(int i = 0; i < maps->fullNameCount; i++)
  {
    ProductionOption* prod = maps->fullNameToOption[i];
    if(!prod) continue;
    fprintf(file, "\ntypedef struct \n{\n  int type;\n  int nodeCount;\n");
    for(int k = 0; k < prod->stepCount; k++)
    {
      char* stepName;
      if(prod->steps[k].token) stepName = prod->steps[k].token->name;
      else
      {
        ProductionExpr* prodExpr = Grammar_getReduced(grammar, prod->steps[k].production);
        if(!prodExpr) prodExpr = prod->steps[k].production;
        stepName = prodExpr->name;
      }
      fprintf(file, "  ProductionNode %s%i;\n", stepName, k);
    }
    fprintf(file, "} %s_%s;\n", namespace, maps->fullNames[i]);
  }

  generateHeaderGuardsEnd(file);
}

static void generateProductionsSource(FILE* file, FullNameMaps* maps, Grammar* grammar, LalrMachine* lalrMachine, char* namespace)
{
  // Visit functions
  char* visitType = "VisitFunction ";
  fprintf(file, "%s%s_visit_defaultFunction = %s_visitNodes;\n\n", visitType, namespace, namespace);
  for(int i = 0; i < maps->fullNameCount; i++)
    fprintf(file, "%s%s_visit_%s = nullptr;\n", visitType, namespace, maps->fullNames[i]);

  fprintf(
    file, "\nbool %s_visitNodes(Production* production, VisitData* visitData){ return visitNodes(production, visitData, %s_visit);}\n", namespace, namespace);
  
  // Node redundancy table
  fprintf(file, "\nbool %s_nodeRedundancyTable[] = {\n  false, // UNKNOWN\n", namespace);
  for(int i = 0; i < maps->fullNameCount; i++)
    if(maps->fullNameToOption[i] != nullptr)
    {
      ProductionOption* prodOption = maps->fullNameToOption[i];
      bool shouldReduce = false;
      if(prodOption->stepCount == 1 && prodOption->steps[0].production)
      {
        ProductionExpr* base = Grammar_getReduced(grammar, &grammar->productions[i]);
        if(!base) base = &grammar->productions[i];
        ProductionExpr* step = Grammar_getReduced(grammar, prodOption->steps[0].production);
        if(!step) step = prodOption->steps[0].production;
        shouldReduce = base == step;
      }
      fprintf(file, "  %s%s //%s\n", shouldReduce ? "true" : "false", i < maps->fullNameCount -1 ? "," : "", maps->fullNames[i]);
    }

  fprintf(file, "};\n");

  // visit function
  fprintf(file, "\nbool %s_visit(Production* production, VisitData* visitData)\n{\n", namespace);
  fprintf(file, "  %s visitFunction = nullptr;\n  switch(production->type)\n  {\n", visitType);
  for(int i = 0; i < maps->fullNameCount; i++)
    if(maps->fullNameToOption[i] != nullptr)
      fprintf(file, "    case %s_P_%s: visitFunction = %s_visit_%s; break;\n", namespace, maps->fullNames[i], namespace, maps->fullNames[i]);

  fprintf(file, "  }\n  if(visitFunction != nullptr) return visitFunction(production, visitData);\n\n");
  
  fprintf(file, "  switch(production->type)\n  {\n");
  for(int i = 0; i < maps->fullNameCount; i++)
    if(maps->fullNameToOption[i] != nullptr)
    {
      char* parentProdFullName = maps->fullNames[maps->prodToFullName[maps->fullNameToOption[i]->base->index]];
      fprintf(file, "    case %s_P_%s: visifction = %s_visit_%s; break;\n", namespace, maps->fullNames[i], namespace, parentProdFullName);
    }
  fprintf(file, "  }\n  if(visitFunction != nullptr) return visitFunction(production, visitData);\n\n");
  fprintf(file, "  return %s_visit_defaultFunction(production, visitData);\n}\n\n", namespace);
}

static int reducesWithLookahead(LalrState* state, TokenExpr* token, LalrItem** out)
{
  int count = 0;
  for(int i = 0; i < state->itemCount; i++)
  {
    LalrItem* item = &state->items[i];
    if(item->position >= item->production->stepCount)
      for(int j = 0; j < item->lookaheadCount; j++)      
        if(item->lookahead[j] == token)
        {
          out[count++] = item;
          break;
        }
  }
  
  return count;
}

static void generateGrammarParser(FILE* file, FullNameMaps* maps, Grammar* grammar, LalrMachine* lalrMachine, char* namespace)
{
  fprintf(file, "Parser %s_parse(Token* tokens, int productionStructSize)\n{\n", namespace);

  for(int i = 0; i < lalrMachine->stateCount; i++)
  {
    int actionCount = 0;
    LalrState* state = lalrMachine->states[i];
    fprintf(file, "  Action state%iActions[] = {\n", i);
    for(int t = 0; t < state->transitionCount; t++)
    {
      TokenExpr* token = state->transitions[t].token;
      if(token)
      {
        if(actionCount++ != 0) fprintf(file, ",\n");
        fprintf(file, "    createShift(%s_T_%s, %i)", namespace, token->name, state->transitions[t].target->index);
      }
    }
    if(state == lalrMachine->acceptedState) fprintf(file, "    createAcceptAction()");
    else for(int j = 0; j <= grammar->tokenCount; j++)
    {
      LalrItem* reductionItems[GRAMMAR_ELEMENTS_MAX];
      TokenExpr* token = (j < grammar->tokenCount) ? &grammar->tokens[j] : nullptr;
      int reductionCount = reducesWithLookahead(state, token, reductionItems);
      if(reductionCount > 0)
      {
        if(actionCount++ != 0) fprintf(file, ",\n");
        char* tokenName = token != nullptr ? token->name : "END_OF_FILE";
        fprintf(file, "    createReduce%i(%s_T_%s", reductionCount, namespace, tokenName);
        for(int k = 0; k < reductionCount; k++)
        {
          int fullNameLength = getProductionFullName(reductionItems[k]->production, grammar, nullptr);
          char fullName[fullNameLength];
          getProductionFullName(reductionItems[k]->production, grammar, fullName);
          fprintf(file, ", %i, %s_P_%s, %i", reductionItems[k]->production->base->index, namespace, fullName, reductionItems[k]->production->stepCount);
        }
        fprintf(file, ")");
      }
    }
    
    fprintf(file, "\n  };\n");
  }

  fprintf(file, "  State states[] = {\n");

  for(int i = 0; i < lalrMachine->stateCount; i++)
  {
    if(i != 0) fprintf(file, ",\n");
    fprintf(file, "    createState(state%iActions, sizeof(state%iActions)/sizeof(Action))", i, i);
  }

  fprintf(file, "\n  };\n  return parse(states, goToTable, token, productionStructSize);\n}\n");
}

static void generateGotoTable(FILE* file, LalrMachine* lalrMachine)
{
  fprintf(file, "static int goToTable(int state, int productionIndex)\n{\n");
  fprintf(file, "  switch(state)\n  {\n");
  for(int i = 0; i < lalrMachine->stateCount; i++)
  {
    LalrState* state = lalrMachine->states[i];
    if(state->transitionCount == 0) continue;
    fprintf(file, "    case %i:\n", i);
    fprintf(file, "    switch(productionIndex)\n    {\n");
    for(int j = 0; j < state->transitionCount; j++)
    {
      LalrTransition* transition = &state->transitions[j];
      if(transition->production)
        fprintf(file, "      case %i: return %i;\n", transition->production->index, transition->target->index);
    }
    fprintf(file, "    }\n");
    fprintf(file, "    break;\n");
  }
  fprintf(file, "  }\n");
  fprintf(file, "}\n\n");
}

static void generateParserSource(FILE* file, FullNameMaps* maps, Grammar* grammar, LalrMachine* lalrMachine, char* namespace)
{
  generatedFileDisclaimer(file);

  fprintf(file, "#include \"parsers/lexer.h\"\n");
  fprintf(file, "#include \"parsers/parser.h\"\n");
  fprintf(file, "#include \"%s/parsers/productions.h\"\n", namespace);
  
  generateLexerSource(file, grammar, namespace);
  generateProductionsSource(file, maps, grammar, lalrMachine, namespace);
  generateGotoTable(file, lalrMachine);
  generateGrammarParser(file, maps, grammar, lalrMachine, namespace);
}

bool generateGrammar(Grammar* grammar, LalrMachine* lalrMachine, char* namespace)
{
  char finalBasePath[STRING_LENGTH*3];

  strcpy(finalBasePath, baseOutputPath);
  strcat(finalBasePath, namespace);
  strcat(finalBasePath, "/");

  createDirectory(generationPath);
  createDirectory(baseOutputPath);
  createDirectory(finalBasePath);

  FullNameMaps maps = createProductionFullNameMaps(grammar);

  FILE* file = createFile(finalBasePath, "parser.h");
  
  if(file)
  {
    generateParserHeader(file, grammar, namespace);  
    closeFile(file);
  }
  
  file = createFile(finalBasePath, "productions.h");
  if(file)
  {
    generateProductionsHeader(file, &maps, grammar, lalrMachine, namespace);
    closeFile(file);
  }

  file = createFile(finalBasePath, "parser.c");
  if(file)
  {
    generateParserSource(file, &maps, grammar, lalrMachine, namespace);
    closeFile(file);
  }

  clearFullNameMaps(&maps);

  return true;
}
